{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dayBJczV5at",
        "outputId": "9ec9e04d-37c1-47c3-9026-c108fdb0e839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "hsDMHvAbWPsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (299, 299)  # Input size for InceptionV3 model\n",
        "batch_size = 32  # Number of images to process in each batch"
      ],
      "metadata": {
        "id": "WYCDAnacdsAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "bomvjEt8dwDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_generator.flow_from_directory(\n",
        "    '../content/drive/MyDrive/MLProject/brain_tumor_dataset',\n",
        "    target_size=input_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_data = data_generator.flow_from_directory(\n",
        "    '../content/drive/MyDrive/MLProject/brain_tumor_dataset',\n",
        "    target_size=input_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOT0N5Fqd0_i",
        "outputId": "a94a8a1d-9bbb-4afa-d3ac-e69877016f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 253 images belonging to 2 classes.\n",
            "Found 253 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the InceptionV3 model (pretrained on ImageNet)\n",
        "base_model = tf.keras.applications.InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(input_size[0], input_size[1], 3)\n",
        ")"
      ],
      "metadata": {
        "id": "y-cLZb41Wbuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "_BOT7n_0egdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "1mHXbIxUWjbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "L0fKFM4xWo8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    validation_data=validation_data,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv7bwPNEWyrp",
        "outputId": "e195b60d-5d33-4463-862a-e2b9de72d84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 201s 24s/step - loss: 0.9674 - accuracy: 0.6640 - val_loss: 0.6869 - val_accuracy: 0.7075\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 152s 20s/step - loss: 0.4060 - accuracy: 0.8063 - val_loss: 0.4992 - val_accuracy: 0.7905\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 151s 20s/step - loss: 0.4238 - accuracy: 0.8261 - val_loss: 0.4632 - val_accuracy: 0.8063\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 155s 21s/step - loss: 0.3364 - accuracy: 0.8696 - val_loss: 0.2608 - val_accuracy: 0.8893\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 152s 20s/step - loss: 0.2924 - accuracy: 0.8893 - val_loss: 0.2715 - val_accuracy: 0.8696\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 152s 20s/step - loss: 0.2718 - accuracy: 0.8893 - val_loss: 0.2526 - val_accuracy: 0.9012\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 150s 20s/step - loss: 0.2499 - accuracy: 0.8893 - val_loss: 0.2144 - val_accuracy: 0.9170\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 138s 19s/step - loss: 0.1857 - accuracy: 0.9289 - val_loss: 0.2456 - val_accuracy: 0.8893\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 151s 20s/step - loss: 0.2980 - accuracy: 0.8458 - val_loss: 0.2133 - val_accuracy: 0.9249\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 152s 20s/step - loss: 0.2355 - accuracy: 0.9091 - val_loss: 0.2030 - val_accuracy: 0.9209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff37582aaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}